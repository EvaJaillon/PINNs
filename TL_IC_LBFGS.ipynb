{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### start with 5 outputs. Freeze. Add more equations/outputs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neurodiffeq.conditions import IVP\n",
    "from neurodiffeq.solvers import Solver2D\n",
    "from neurodiffeq.monitors import Monitor2D\n",
    "from neurodiffeq.generators import Generator2D\n",
    "import torch\n",
    "from neurodiffeq import diff      # the differentiation operation\n",
    "from neurodiffeq.ode import solve # the ANN-based solver\n",
    "from neurodiffeq.conditions import IVP   # the initial condition\n",
    "from neurodiffeq.networks import FCNN    # fully-connect neural network\n",
    "from neurodiffeq.networks import SinActv # sin activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale en temps\n",
    "mu = 0.1      # viscosité\n",
    "#f = [0]*8     # fonctions de forçage constantes ici\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "x = np.linspace(0, X, nx)\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "# IC \n",
    "def init_cond():\n",
    "    rho = 2+np.sin(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# spatial derivation\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Function ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) + f[0]\n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) + f[1])\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) + f[2])\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) + f[3])\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) + f[4]\n",
    "    dBx_dt = np.zeros_like(Bx) + f[5]\n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) + f[6])\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) + f[7])\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# solver\n",
    "y0 = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, [0, L], y0, method='RK45', t_eval=np.linspace(0, L, 300))\n",
    "\n",
    "# Show variable (ex: vx)\n",
    "vx_sol = sol.y[nx:2*nx, :]  # vx \n",
    "plt.imshow(vx_sol, extent=[0, L, 0, X], aspect='auto', origin='lower')\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Espace (x)\")\n",
    "plt.title(\"vx(x,t)\")\n",
    "plt.colorbar(label=\"vx\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solver \n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "X = 1.0       # spatial domain length\n",
    "nx = 300      # number of spacial points \n",
    "L = 1.0       # time\n",
    "mu = 0.1      # viscosity\n",
    "#f = [0]*8     # \n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Return (8, N)\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "x = np.linspace(0, X, nx)\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "# IC\n",
    "def init_cond():\n",
    "    rho = 2+np.sin(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) + f[0]\n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) + f[1])\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) + f[2])\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) + f[3])\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) + f[4]\n",
    "    dBx_dt = np.zeros_like(Bx) + f[5]\n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) + f[6])\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) + f[7])\n",
    "\n",
    "    # Variables fixes :  rho(0)=2, vx=vy=vz=0  --> dérivées temporelles = 0\n",
    "    drho_dt[0] = 0.0\n",
    "    dvx_dt[0]  = 0.0\n",
    "    dvy_dt[0]  = 0.0\n",
    "    dvz_dt[0]  = 0.0\n",
    "\n",
    "    # Variables imposées = exp(-t)  -->  d/dt exp(-t) = -exp(-t)\n",
    "    bc_dot = -np.exp(-t)\n",
    "    dP_dt[0]  = bc_dot\n",
    "    dBx_dt[0] = bc_dot\n",
    "    dBy_dt[0] = bc_dot\n",
    "    dBz_dt[0] = bc_dot\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "#Lancement du solveur\n",
    "y0 = init_cond()\n",
    "tspan = (0.0, L)\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "sol = solve_ivp( mhd_rhs, tspan, y0,method='RK45',t_eval=t_eval)\n",
    "\n",
    "# Affichage d'une variable au cours du temps (ex: vx)\n",
    "vx_sol = sol.y[nx:2*nx, :]\n",
    "plt.imshow(vx_sol, extent=[0, L, 0, X],aspect='auto', origin='lower')\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Position x\")\n",
    "plt.title(\"vx(x,t)\")\n",
    "plt.colorbar(label=\"vx\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur with ff : works well\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2+np.sin(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) + f[0]\n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) + f[1])\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) + f[2])\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) + f[3])\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) + f[4]\n",
    "    dBx_dt = np.zeros_like(Bx) + f[5]\n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) + f[6])\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) + f[7])\n",
    "\n",
    "    # Variables fixes :  rho(0)=2, vx=vy=vz=0  --> dérivées temporelles = 0\n",
    "    drho_dt[0] = 0.0\n",
    "    dvx_dt[0]  = 0.0\n",
    "    dvy_dt[0]  = 0.0\n",
    "    dvz_dt[0]  = 0.0\n",
    "\n",
    "    # Variables imposées = exp(-t)  -->  d/dt exp(-t) = -exp(-t)\n",
    "    bc_dot = -np.exp(-t)\n",
    "    dP_dt[0]  = bc_dot\n",
    "    dBx_dt[0] = bc_dot\n",
    "    dBy_dt[0] = bc_dot\n",
    "    dBz_dt[0] = bc_dot\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num = sol.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur without ff\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2+np.sin(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Variables fixes :  rho(0)=2, vx=vy=vz=0  --> dérivées temporelles = 0\n",
    "    drho_dt[0] = 0.0\n",
    "    dvx_dt[0]  = 0.0\n",
    "    dvy_dt[0]  = 0.0\n",
    "    dvz_dt[0]  = 0.0\n",
    "\n",
    "    # Variables imposées = exp(-t)  -->  d/dt exp(-t) = -exp(-t)\n",
    "    bc_dot = -np.exp(-t)\n",
    "    dP_dt[0]  = bc_dot\n",
    "    dBx_dt[0] = bc_dot\n",
    "    dBy_dt[0] = bc_dot\n",
    "    dBz_dt[0] = bc_dot\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num = sol.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur without ff\n",
    "### direct BC\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2+np.sin(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num = sol.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TL on IC\n",
    "\n",
    "from neurodiffeq.networks import FCNN\n",
    "from neurodiffeq.generators import Generator2D\n",
    "from neurodiffeq.operators import diff\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Définition d'un réseau avec deux têtes\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # Têtes séparées\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "    \n",
    "    def forward(self, x, head_idx=0):\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        else:\n",
    "            return self.head2(shared)\n",
    "\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "\n",
    "# Paramètre mu unique\n",
    "mu = 0.3  # Valeur fixe pour mu\n",
    "\n",
    "# Définition des conditions initiales pour chaque tête\n",
    "initial_conditions = [\n",
    "    # Head 0 - CI originales\n",
    "    {\n",
    "        'rho': lambda x: torch.sin(x),\n",
    "        'v': lambda x: x*x,\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x)\n",
    "    },\n",
    "    # Head 1 - Nouvelles CI\n",
    "    {\n",
    "        'rho': lambda x: torch.sin(x),\n",
    "        'v': lambda x: torch.ones_like(x),\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x) \n",
    "    }\n",
    "]\n",
    "\n",
    "# Fonctions de forçage pour chaque tête\n",
    "# (Vous les remplacerez par vos propres calculs)\n",
    "\n",
    "\n",
    "\n",
    "# PDE system adapté pour sélectionner le bon forçage selon la tête\n",
    "def pde_system(rho, v, P, By, Bz, x, t, head_idx):\n",
    "   \n",
    "    return [\n",
    "        diff(rho, t) + v * diff(rho, x) + rho * diff(v, x) ,\n",
    "        rho * diff(v, t) + rho * v * diff(v, x) + diff(P, x) - rho * mu * diff(v, x, order=2) ,\n",
    "        diff(P, t) + P * diff(v, x) + v * diff(P, x) \n",
    "    ]\n",
    "\n",
    "# Création des réseaux avec deux têtes chacun\n",
    "nets = [MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256]) for _ in range(5)]\n",
    "\n",
    "# Optimizer\n",
    "params = [p for net in nets for p in net.parameters()]\n",
    "optimizer = optim.Adam(params, lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Generators\n",
    "train_gen = Generator2D((20, 20), xy_min=(0, 0), xy_max=(1, 1), method='equally-spaced-noisy')\n",
    "ic_x = torch.linspace(0, 1, 128).view(-1, 1)\n",
    "ic_t = torch.zeros_like(ic_x)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(12000)):\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    epoch_pde_loss = 0\n",
    "    epoch_ic_loss = 0\n",
    "    \n",
    "    # Pour chaque tête (et chaque set de CI correspondant)\n",
    "    for head_idx in range(len(initial_conditions)):\n",
    "        # 1. PDE Loss\n",
    "        samples = train_gen.get_examples()\n",
    "        x_train = samples[0].view(-1, 1)\n",
    "        t_train = samples[1].view(-1, 1)\n",
    "        inputs = torch.cat((x_train, t_train), dim=1)\n",
    "\n",
    "        # Utilisation de la tête spécifique\n",
    "        outputs = [net(inputs, head_idx=head_idx) for net in nets]\n",
    "        pde_residuals = pde_system(*outputs, x_train, t_train, head_idx)\n",
    "\n",
    "        loss_pde = sum([criterion(residual, torch.zeros_like(residual)) for residual in pde_residuals])\n",
    "        epoch_pde_loss += loss_pde.item()\n",
    "\n",
    "        # 2. Initial condition loss (spécifique à chaque tête)\n",
    "        ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "        ic_outputs = [net(ic_inputs, head_idx=head_idx) for net in nets]\n",
    "        ic_targets = [\n",
    "            initial_conditions[head_idx]['rho'](ic_x),\n",
    "            initial_conditions[head_idx]['v'](ic_x),\n",
    "            initial_conditions[head_idx]['P'](ic_x),\n",
    "            initial_conditions[head_idx]['By'](ic_x),\n",
    "            initial_conditions[head_idx]['Bz'](ic_x)\n",
    "        ]\n",
    "\n",
    "        loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "        epoch_ic_loss += loss_ic.item()\n",
    "\n",
    "        # Accumulation de la perte totale\n",
    "        total_loss += loss_pde + loss_ic\n",
    "    \n",
    "    # Rétropropagation\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        avg_pde_loss = epoch_pde_loss / len(initial_conditions)\n",
    "        avg_ic_loss = epoch_ic_loss / len(initial_conditions)\n",
    "        avg_total_loss = total_loss.item() / len(initial_conditions)\n",
    "        print(f\"Epoch {epoch} | Avg Loss PDE: {avg_pde_loss:.3e} | Avg Loss IC: {avg_ic_loss:.3e} | Avg Total: {avg_total_loss:.3e}\")\n",
    "    \n",
    "    total_losses.append(total_loss.item() / len(initial_conditions))\n",
    "    pde_losses.append(epoch_pde_loss / len(initial_conditions))\n",
    "    ic_losses.append(epoch_ic_loss / len(initial_conditions))\n",
    "\n",
    "# Fonction pour obtenir les solutions\n",
    "def solutions(x, t, head_idx=0):\n",
    "    inputs = torch.cat((x, t), dim=1)\n",
    "    return [net(inputs, head_idx=head_idx).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PINN training 1 without ff, with BC\n",
    "\n",
    "\n",
    "from neurodiffeq.networks import FCNN\n",
    "from neurodiffeq.generators import Generator2D\n",
    "from neurodiffeq.operators import diff\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Définition d'un réseau avec deux têtes\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # Têtes séparées\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "    \n",
    "    def forward(self, x, head_idx=0):\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        else:\n",
    "            return self.head2(shared)\n",
    "\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "bc_losses = []  # Nouveau: pour suivre la loss des conditions aux limites\n",
    "\n",
    "# Paramètre mu unique\n",
    "mu = 0.3\n",
    "\n",
    "# Conditions initiales et aux limites\n",
    "initial_conditions = [\n",
    "    # Head 0\n",
    "    {\n",
    "        'rho': lambda x: 2+torch.sin(x),\n",
    "        'v': lambda x: x,\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x)\n",
    "    },\n",
    "    # Head 1 \n",
    "    {\n",
    "        'rho': lambda x: 2+torch.sin(x),\n",
    "        'v': lambda x: x*x*x,\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x) \n",
    "    }\n",
    "]\n",
    "\n",
    "# Nouveau: Conditions aux limites (communes aux deux têtes)\n",
    "def boundary_conditions(x, t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(x),\n",
    "        'v': torch.zeros_like(x),\n",
    "        'P': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t)\n",
    "\n",
    "    }\n",
    "\n",
    "# PDE system\n",
    "def pde_system(rho, v, P, By, Bz, x, t, head_idx):\n",
    "    return [\n",
    "        diff(rho, t) + v * diff(rho, x) + rho * diff(v, x),\n",
    "        rho * diff(v, t) + rho * v * diff(v, x) + diff(P, x) - rho * mu * diff(v, x, order=2),\n",
    "        diff(P, t) + P * diff(v, x) + v * diff(P, x)\n",
    "    ]\n",
    "\n",
    "# Création des réseaux\n",
    "nets = [MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256]) for _ in range(5)]\n",
    "\n",
    "# Optimizer\n",
    "params = [p for net in nets for p in net.parameters()]\n",
    "optimizer = optim.Adam(params, lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Generators\n",
    "train_gen = Generator2D((20, 20), xy_min=(0, 0), xy_max=(1, 1), method='equally-spaced-noisy')\n",
    "bc_gen = Generator2D((20, 20), xy_min=(0, 0), xy_max=(0, 1), method='equally-spaced')  # Points au bord x=0\n",
    "ic_x = torch.linspace(0, 1, 128).view(-1, 1)\n",
    "ic_t = torch.zeros_like(ic_x)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(12000)):\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    epoch_pde_loss = 0\n",
    "    epoch_ic_loss = 0\n",
    "    epoch_bc_loss = 0  # Nouveau: loss des conditions aux limites\n",
    "    \n",
    "    for head_idx in range(len(initial_conditions)):\n",
    "        # 1. PDE Loss\n",
    "        samples = train_gen.get_examples()\n",
    "        x_train = samples[0].view(-1, 1)\n",
    "        t_train = samples[1].view(-1, 1)\n",
    "        inputs = torch.cat((x_train, t_train), dim=1)\n",
    "\n",
    "        outputs = [net(inputs, head_idx=head_idx) for net in nets]\n",
    "        pde_residuals = pde_system(*outputs, x_train, t_train, head_idx)\n",
    "        loss_pde = sum([criterion(residual, torch.zeros_like(residual)) for residual in pde_residuals])\n",
    "        epoch_pde_loss += loss_pde.item()\n",
    "\n",
    "        # 2. Initial condition loss\n",
    "        ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "        ic_outputs = [net(ic_inputs, head_idx=head_idx) for net in nets]\n",
    "        ic_targets = [\n",
    "            initial_conditions[head_idx]['rho'](ic_x),\n",
    "            initial_conditions[head_idx]['v'](ic_x),\n",
    "            initial_conditions[head_idx]['P'](ic_x),\n",
    "            initial_conditions[head_idx]['By'](ic_x),\n",
    "            initial_conditions[head_idx]['Bz'](ic_x)\n",
    "        ]\n",
    "        loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "        epoch_ic_loss += loss_ic.item()\n",
    "\n",
    "        # 3. Nouveau: Boundary condition loss (x=0)\n",
    "        bc_samples = bc_gen.get_examples()\n",
    "        x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1)  # x=0\n",
    "        t_bc = bc_samples[1].view(-1, 1)\n",
    "        bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "        \n",
    "        bc_outputs = [net(bc_inputs, head_idx=head_idx) for net in nets]\n",
    "        bc_targets = boundary_conditions(x_bc, t_bc)\n",
    "        loss_bc = (\n",
    "            criterion(bc_outputs[0], bc_targets['rho']) +  # rho\n",
    "            criterion(bc_outputs[1], bc_targets['v']) +    # v\n",
    "            criterion(bc_outputs[2], bc_targets['P']) +    # P\n",
    "            criterion(bc_outputs[3], bc_targets['By']) +   # By\n",
    "            criterion(bc_outputs[4], bc_targets['Bz'])     # Bz\n",
    "        )\n",
    "        epoch_bc_loss += loss_bc.item()\n",
    "\n",
    "        total_loss += loss_pde + loss_ic + loss_bc  # Inclut maintenant la loss BC\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        n_heads = len(initial_conditions)\n",
    "        print(\n",
    "            f\"Epoch {epoch} | \"\n",
    "            f\"PDE: {epoch_pde_loss/n_heads:.3e} | \"\n",
    "            f\"IC: {epoch_ic_loss/n_heads:.3e} | \"\n",
    "            f\"BC: {epoch_bc_loss/n_heads:.3e} | \"  # Nouveau: affichage BC\n",
    "            f\"Total: {total_loss.item()/n_heads:.3e}\"\n",
    "        )\n",
    "    \n",
    "    total_losses.append(total_loss.item() / len(initial_conditions))\n",
    "    pde_losses.append(epoch_pde_loss / len(initial_conditions))\n",
    "    ic_losses.append(epoch_ic_loss / len(initial_conditions))\n",
    "    bc_losses.append(epoch_bc_loss / len(initial_conditions))  # Stocke la loss BC\n",
    "\n",
    "def solutions(x, t, head_idx=0):\n",
    "    inputs = torch.cat((x, t), dim=1)\n",
    "    return [net(inputs, head_idx=head_idx).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(total_losses, label='Total Loss')\n",
    "plt.semilogy(pde_losses, label='PDE Loss', linestyle='--')\n",
    "plt.semilogy(ic_losses, label='IC Loss', linestyle=':')\n",
    "plt.semilogy(bc_losses, label='BC Loss', linestyle='-')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Training Loss Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shox rho for 2 heads\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "\n",
    "# 1. Vérification des types de données\n",
    "print(f\"Type des poids du premier réseau: {next(nets[0].parameters()).dtype}\")\n",
    "\n",
    "# 2. Création du maillage\n",
    "x = np.linspace(0, 1, 100).astype(np.float32)\n",
    "t = np.linspace(0, 1, 50).astype(np.float32)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# 3. Conversion en tenseurs PyTorch\n",
    "x_tensor = torch.tensor(X.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 4. Calcul des solutions pour les deux têtes\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Vérification et conversion si nécessaire\n",
    "        if next(nets[0].parameters()).dtype != torch.float32:\n",
    "            for net in nets:\n",
    "                net.float()\n",
    "        \n",
    "        # Calcul pour les deux têtes\n",
    "        sols_head1 = solutions(x_tensor, t_tensor, head_idx=0)  # mu=0.1\n",
    "        sols_head2 = solutions(x_tensor, t_tensor, head_idx=1)  # mu=0.5\n",
    "        \n",
    "        rho_head1 = sols_head1[0].cpu().numpy().reshape(X.shape)\n",
    "        rho_head2 = sols_head2[0].cpu().numpy().reshape(X.shape)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Solution analytique\n",
    "rho_analytical = 2+ np.sin(X) * np.exp(-T)\n",
    "\n",
    "# Calcul des erreurs\n",
    "error_head1 = np.abs(rho_analytical - rho_head1)\n",
    "error_head2 = np.abs(rho_analytical - rho_head2)\n",
    "\n",
    "# Création d'une figure avec 4 sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaison of the solutions ρ(x,t) for the 2 heads', fontsize=16)\n",
    "\n",
    "# Graphique pour mu=0.1\n",
    "im1 = axes[0,0].pcolormesh(X, T, rho_head1, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im1, ax=axes[0,0], label='ρ(x,t)')\n",
    "axes[0,0].set_title('Solution ρ(x,t) - Head 1 (μ=0.1)')\n",
    "axes[0,0].set_xlabel('x')\n",
    "axes[0,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.1\n",
    "im2 = axes[0,1].pcolormesh(X, T, error_head1, shading='auto', cmap='hot')\n",
    "fig.colorbar(im2, ax=axes[0,1], label='Absolute erreur ')\n",
    "axes[0,1].set_title('Erreur - Head 1 (μ=0.1)')\n",
    "axes[0,1].set_xlabel('x')\n",
    "axes[0,1].set_ylabel('t')\n",
    "\n",
    "# Graphique pour mu=0.5\n",
    "im3 = axes[1,0].pcolormesh(X, T, rho_head2, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im3, ax=axes[1,0], label='ρ(x,t)')\n",
    "axes[1,0].set_title('Solution ρ(x,t) - Head 2 (μ=0.5)')\n",
    "axes[1,0].set_xlabel('x')\n",
    "axes[1,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.5\n",
    "im4 = axes[1,1].pcolormesh(X, T, error_head2, shading='auto', cmap='hot')\n",
    "fig.colorbar(im4, ax=axes[1,1], label='Absolute erreur ')\n",
    "axes[1,1].set_title('Erreur - Head 2 (μ=0.5)')\n",
    "axes[1,1].set_xlabel('x')\n",
    "axes[1,1].set_ylabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs maximales pour comparaison\n",
    "print(f\"Erreur maximale tête 1 (μ=0.1): {np.max(error_head1):.3e}\")\n",
    "print(f\"Erreur maximale tête 2 (μ=0.5): {np.max(error_head2):.3e}\")\n",
    "\n",
    "# Optionnel: Différence entre les deux têtes\n",
    "diff_heads = np.abs(rho_head1 - rho_head2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(X, T, diff_heads, shading='auto', cmap='plasma')\n",
    "plt.colorbar(label='Difference')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Difference between the 2 heads')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "\n",
    "##vx\n",
    "\n",
    "# 1. Vérification des types de données\n",
    "print(f\"Type des poids du premier réseau: {next(nets[1].parameters()).dtype}\")\n",
    "\n",
    "# 2. Création du maillage\n",
    "x = np.linspace(0, 1, 100).astype(np.float32)\n",
    "t = np.linspace(0, 1, 50).astype(np.float32)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# 3. Conversion en tenseurs PyTorch\n",
    "x_tensor = torch.tensor(X.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 4. Calcul des solutions pour les deux têtes\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Vérification et conversion si nécessaire\n",
    "        if next(nets[1].parameters()).dtype != torch.float32:\n",
    "            for net in nets:\n",
    "                net.float()\n",
    "        \n",
    "        # Calcul pour les deux têtes\n",
    "        sols_head1 = solutions(x_tensor, t_tensor, head_idx=0)  # mu=0.1\n",
    "        sols_head2 = solutions(x_tensor, t_tensor, head_idx=1)  # mu=0.5\n",
    "        \n",
    "        rho_head1 = sols_head1[1].cpu().numpy().reshape(X.shape)\n",
    "        rho_head2 = sols_head2[1].cpu().numpy().reshape(X.shape)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Solution analytique\n",
    "rho_analytical1 =  x*np.exp(-T)\n",
    "rho_analytical2 =  x*x*x*np.exp(-T)\n",
    "\n",
    "# Calcul des erreurs\n",
    "error_head1 = np.abs(rho_analytical1 - rho_head1)\n",
    "error_head2 = np.abs(rho_analytical2 - rho_head2)\n",
    "\n",
    "# Création d'une figure avec 4 sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaison of vx(x,t) for the 2 heads', fontsize=16)\n",
    "\n",
    "# Graphique pour mu=0.1\n",
    "im1 = axes[0,0].pcolormesh(X, T, rho_head1, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im1, ax=axes[0,0], label='vx(x,t)')\n",
    "axes[0,0].set_title('Solution vx(x,t) - Head 1 (μ=0.1)')\n",
    "axes[0,0].set_xlabel('x')\n",
    "axes[0,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.1\n",
    "im2 = axes[0,1].pcolormesh(X, T, error_head1, shading='auto', cmap='hot')\n",
    "fig.colorbar(im2, ax=axes[0,1], label='Absolute error')\n",
    "axes[0,1].set_title('Error - Head 1 (μ=0.1)')\n",
    "axes[0,1].set_xlabel('x')\n",
    "axes[0,1].set_ylabel('t')\n",
    "\n",
    "# Graphique pour mu=0.5\n",
    "im3 = axes[1,0].pcolormesh(X, T, rho_head2, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im3, ax=axes[1,0], label='vx(x,t)')\n",
    "axes[1,0].set_title('Solution vx(x,t) - Head 2 (μ=0.5)')\n",
    "axes[1,0].set_xlabel('x')\n",
    "axes[1,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.5\n",
    "im4 = axes[1,1].pcolormesh(X, T, error_head2, shading='auto', cmap='hot')\n",
    "fig.colorbar(im4, ax=axes[1,1], label='Absolute error ')\n",
    "axes[1,1].set_title('Error - Head 2 (μ=0.5)')\n",
    "axes[1,1].set_xlabel('x')\n",
    "axes[1,1].set_ylabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs maximales pour comparaison\n",
    "print(f\"Erreur maximale tête 1 (μ=0.1): {np.max(error_head1):.3e}\")\n",
    "print(f\"Erreur maximale tête 2 (μ=0.5): {np.max(error_head2):.3e}\")\n",
    "\n",
    "# Optionnel: Différence entre les deux têtes\n",
    "diff_heads = np.abs(rho_head1 - rho_head2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(X, T, diff_heads, shading='auto', cmap='plasma')\n",
    "plt.colorbar(label='Difference')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Difference between the 2 heads')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save NN after training\n",
    "# for i, net in enumerate(nets):\n",
    "#     torch.save(net.state_dict(), f\"net_{i}.pth\")\n",
    "\n",
    "## save weights of the 5 first NN\n",
    "\n",
    "import os\n",
    "os.makedirs(\"saved_weights\", exist_ok=True)  \n",
    "\n",
    "\n",
    "for i, net in enumerate(nets[:5]):\n",
    "    torch.save(net.state_dict(), f\"saved_weights/net_{i}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training 2 without ff, with BC\n",
    "\n",
    "from neurodiffeq.networks import FCNN\n",
    "from neurodiffeq.generators import Generator2D\n",
    "from neurodiffeq.operators import diff\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Définition d'un réseau avec deux têtes\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # Têtes séparées\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "    \n",
    "    def forward(self, x, head_idx=0):\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        else:\n",
    "            return self.head2(shared)\n",
    "\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "\n",
    "# Paramètre mu unique\n",
    "mu = 0.3  # Valeur fixe pour mu\n",
    "\n",
    "# Définition des conditions initiales pour chaque tête\n",
    "initial_conditions = [\n",
    "    # Head 0 - CI originales\n",
    "    {\n",
    "        'rho': lambda x: 2+torch.sin(x),\n",
    "        'v': lambda x: x,\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x),\n",
    "        'vy': lambda x: x,\n",
    "        'vz': lambda x: x,\n",
    "        'Bx': lambda x: torch.exp(-x)\n",
    "    },\n",
    "    # Head 1 - Nouvelles CI\n",
    "    {\n",
    "        'rho': lambda x: 2+torch.sin(x),\n",
    "        'v': lambda x: x*x*x,\n",
    "        'P': lambda x: torch.exp(-x),\n",
    "        'By': lambda x: torch.exp(-x),\n",
    "        'Bz': lambda x: torch.exp(-x),\n",
    "        'vy': lambda x: x*x*x,  \n",
    "        'vz': lambda x: x*x*x,\n",
    "        'Bx': lambda x: torch.exp(-x)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Nouveau: Conditions aux limites (communes aux deux têtes)\n",
    "def boundary_conditions(x, t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(x),\n",
    "        'v': torch.zeros_like(x),\n",
    "        'P': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t),\n",
    "        'vy': torch.zeros_like(x),\n",
    "        'vz': torch.zeros_like(x),\n",
    "        'Bx': torch.exp(-t),\n",
    "    }\n",
    "\n",
    "# PDE system adapté pour 8 équations\n",
    "def pde_system(rho, vx, P, By, Bz, vy, vz, Bx, x, t, head_idx):\n",
    "   \n",
    "    return [\n",
    "        diff(rho, t) + vx * diff(rho, x) + rho * diff(vx, x) ,  # Équation 1\n",
    "        rho * diff(vx, t) + rho * vx * diff(vx, x) + diff(P, x) + By * diff(By, x) + Bz * diff(Bz, x) - rho * mu * diff(vx, x, order=2)  ,  # Équation 2\n",
    "        rho * diff(vy,t) + rho*vx*diff(vy,x) - Bx*diff(By,x) ,  # Équation 3\n",
    "        rho * diff(vz,t) + rho*vx*diff(vz,x) - Bx*diff(Bz,x) ,  # Nouvelle équation 4\n",
    "        diff(P,t) + P*diff(vx,x) + vx*diff(P,x),  # Nouvelle équation 5\n",
    "        diff(Bx,t),  # Nouvelle équation 6\n",
    "        diff(By,t) + vx*diff(By,x) + By*diff(vx,x) - Bx*diff(vy,x) ,  # Nouvelle équation 7\n",
    "        diff(Bz,t) + vx*diff(Bz,x) + Bz*diff(vx,x) - Bx*diff(vz,x)  # Nouvelle équation 8\n",
    "    ]\n",
    "\n",
    "# Création des 8 réseaux\n",
    "nets = [MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256]) for _ in range(8)]\n",
    "\n",
    "# Chargement des poids sauvegardés pour les 5 premiers réseaux\n",
    "for i in range(5):\n",
    "    net_path = f\"saved_weights/net_{i}.pt\"\n",
    "    if os.path.exists(net_path):\n",
    "        nets[i].load_state_dict(torch.load(net_path))\n",
    "        #print(f\"Poids chargés pour le réseau {i} depuis {net_path}\")\n",
    "    else:\n",
    "        #print(f\"Attention: Fichier {net_path} non trouvé. Initialisation aléatoire.\")\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        nets[i].apply(init_weights)\n",
    "\n",
    "# # Initialisation des nouveaux réseaux (5 à 7) avec des poids aléatoires\n",
    "for i in range(5, 8):\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "    nets[i].apply(init_weights)\n",
    "    #print(f\"Réseau {i} initialisé avec des poids aléatoires\")\n",
    "\n",
    "# Optimizer\n",
    "params = [p for net in nets for p in net.parameters()]\n",
    "optimizer = optim.Adam(params, lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "##define the exponential learning rate decay scheduler\n",
    "step_size = 500 ##how often the exponential decay is applied\n",
    "gamma = 0.975 ##exponential decay scale\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "\n",
    "# Generators\n",
    "train_gen = Generator2D((20, 20), xy_min=(0, 0), xy_max=(1, 1), method='equally-spaced-noisy')\n",
    "ic_x = torch.linspace(0, 1, 128).view(-1, 1)\n",
    "ic_t = torch.zeros_like(ic_x)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(12000)):\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    epoch_pde_loss = 0\n",
    "    epoch_ic_loss = 0\n",
    "    \n",
    "    # Pour chaque tête\n",
    "    for head_idx in range(len(initial_conditions)):\n",
    "        # 1. PDE Loss\n",
    "        samples = train_gen.get_examples()\n",
    "        x_train = samples[0].view(-1, 1)\n",
    "        t_train = samples[1].view(-1, 1)\n",
    "        inputs = torch.cat((x_train, t_train), dim=1)\n",
    "\n",
    "        # Utilisation de la tête spécifique\n",
    "        outputs = [net(inputs, head_idx=head_idx) for net in nets]\n",
    "        pde_residuals = pde_system(*outputs, x_train, t_train, head_idx)\n",
    "\n",
    "        loss_pde = sum([criterion(residual, torch.zeros_like(residual)) for residual in pde_residuals])\n",
    "        epoch_pde_loss += loss_pde.item()\n",
    "\n",
    "        # 2. Initial condition loss\n",
    "        ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "        ic_outputs = [net(ic_inputs, head_idx=head_idx) for net in nets]\n",
    "        ic_targets = [\n",
    "            initial_conditions[head_idx]['rho'](ic_x),\n",
    "            initial_conditions[head_idx]['v'](ic_x),\n",
    "            initial_conditions[head_idx]['P'](ic_x),\n",
    "            initial_conditions[head_idx]['By'](ic_x),\n",
    "            initial_conditions[head_idx]['Bz'](ic_x),\n",
    "            initial_conditions[head_idx]['vy'](ic_x),\n",
    "            initial_conditions[head_idx]['vz'](ic_x),\n",
    "            initial_conditions[head_idx]['Bx'](ic_x)\n",
    "        ]\n",
    "\n",
    "        loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "        epoch_ic_loss += loss_ic.item()\n",
    "\n",
    "        # 3. Nouveau: Boundary condition loss (x=0)\n",
    "        bc_samples = bc_gen.get_examples()\n",
    "        x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1)  # x=0\n",
    "        t_bc = bc_samples[1].view(-1, 1)\n",
    "        bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "        \n",
    "        bc_outputs = [net(bc_inputs, head_idx=head_idx) for net in nets]\n",
    "        bc_targets = boundary_conditions(x_bc, t_bc)\n",
    "        loss_bc = (\n",
    "            criterion(bc_outputs[0], bc_targets['rho']) +  # rho\n",
    "            criterion(bc_outputs[1], bc_targets['v']) +    # v\n",
    "            criterion(bc_outputs[2], bc_targets['P']) +    # P\n",
    "            criterion(bc_outputs[3], bc_targets['By']) +   # By\n",
    "            criterion(bc_outputs[4], bc_targets['Bz']) +    # Bz\n",
    "            criterion(bc_outputs[5], bc_targets['vy']) + # vy\n",
    "            criterion(bc_outputs[6], bc_targets['vz']) +  # vz\n",
    "            criterion(bc_outputs[7], bc_targets['Bx'])    # Bx\n",
    "        )\n",
    "        epoch_bc_loss += loss_bc.item()\n",
    "\n",
    "        total_loss += loss_pde + loss_ic + loss_bc  # Inclut maintenant la loss BC\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        n_heads = len(initial_conditions)\n",
    "        print(\n",
    "            f\"Epoch {epoch} | \"\n",
    "            f\"PDE: {epoch_pde_loss/n_heads:.3e} | \"\n",
    "            f\"IC: {epoch_ic_loss/n_heads:.3e} | \"\n",
    "            f\"BC: {epoch_bc_loss/n_heads:.3e} | \"  # Nouveau: affichage BC\n",
    "            f\"Total: {total_loss.item()/n_heads:.3e}\"\n",
    "        )\n",
    "    \n",
    "    total_losses.append(total_loss.item() / len(initial_conditions))\n",
    "    pde_losses.append(epoch_pde_loss / len(initial_conditions))\n",
    "    ic_losses.append(epoch_ic_loss / len(initial_conditions))\n",
    "    bc_losses.append(epoch_bc_loss / len(initial_conditions))  # Stocke la loss BC\n",
    "\n",
    "def solutions(x, t, head_idx=0):\n",
    "    inputs = torch.cat((x, t), dim=1)\n",
    "    return [net(inputs, head_idx=head_idx).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(total_losses, label='Total Loss')\n",
    "plt.semilogy(pde_losses, label='PDE Loss', linestyle='--')\n",
    "plt.semilogy(ic_losses, label='IC Loss', linestyle=':')\n",
    "plt.semilogy(bc_losses, label='BC Loss', linestyle='-')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Training Loss Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show rho for 2 heads\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "\n",
    "# 1. Vérification des types de données\n",
    "print(f\"Type des poids du premier réseau: {next(nets[0].parameters()).dtype}\")\n",
    "\n",
    "# 2. Création du maillage\n",
    "x = np.linspace(0, 1, 100).astype(np.float32)\n",
    "t = np.linspace(0, 1, 50).astype(np.float32)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# 3. Conversion en tenseurs PyTorch\n",
    "x_tensor = torch.tensor(X.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 4. Calcul des solutions pour les deux têtes\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Vérification et conversion si nécessaire\n",
    "        if next(nets[0].parameters()).dtype != torch.float32:\n",
    "            for net in nets:\n",
    "                net.float()\n",
    "        \n",
    "        # Calcul pour les deux têtes\n",
    "        sols_head1 = solutions(x_tensor, t_tensor, head_idx=0)  # mu=0.1\n",
    "        sols_head2 = solutions(x_tensor, t_tensor, head_idx=1)  # mu=0.5\n",
    "        \n",
    "        rho_head1 = sols_head1[0].cpu().numpy().reshape(X.shape)\n",
    "        rho_head2 = sols_head2[0].cpu().numpy().reshape(X.shape)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Solution analytique\n",
    "rho_analytical = 2+ np.sin(X) * np.exp(-T)\n",
    "\n",
    "# Calcul des erreurs\n",
    "error_head1 = np.abs(rho_analytical - rho_head1)\n",
    "error_head2 = np.abs(rho_analytical - rho_head2)\n",
    "\n",
    "# Création d'une figure avec 4 sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaison of the solutions ρ(x,t) for the 2 heads', fontsize=16)\n",
    "\n",
    "# Graphique pour mu=0.1\n",
    "im1 = axes[0,0].pcolormesh(X, T, rho_head1, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im1, ax=axes[0,0], label='ρ(x,t)')\n",
    "axes[0,0].set_title('Solution ρ(x,t) - Head 1 (μ=0.1)')\n",
    "axes[0,0].set_xlabel('x')\n",
    "axes[0,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.1\n",
    "im2 = axes[0,1].pcolormesh(X, T, error_head1, shading='auto', cmap='hot')\n",
    "fig.colorbar(im2, ax=axes[0,1], label='Absolute erreur ')\n",
    "axes[0,1].set_title('Erreur - Head 1 (μ=0.1)')\n",
    "axes[0,1].set_xlabel('x')\n",
    "axes[0,1].set_ylabel('t')\n",
    "\n",
    "# Graphique pour mu=0.5\n",
    "im3 = axes[1,0].pcolormesh(X, T, rho_head2, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im3, ax=axes[1,0], label='ρ(x,t)')\n",
    "axes[1,0].set_title('Solution ρ(x,t) - Head 2 (μ=0.5)')\n",
    "axes[1,0].set_xlabel('x')\n",
    "axes[1,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.5\n",
    "im4 = axes[1,1].pcolormesh(X, T, error_head2, shading='auto', cmap='hot')\n",
    "fig.colorbar(im4, ax=axes[1,1], label='Absolute erreur ')\n",
    "axes[1,1].set_title('Erreur - Head 2 (μ=0.5)')\n",
    "axes[1,1].set_xlabel('x')\n",
    "axes[1,1].set_ylabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs maximales pour comparaison\n",
    "print(f\"Erreur maximale tête 1 (μ=0.1): {np.max(error_head1):.3e}\")\n",
    "print(f\"Erreur maximale tête 2 (μ=0.5): {np.max(error_head2):.3e}\")\n",
    "\n",
    "# Optionnel: Différence entre les deux têtes\n",
    "diff_heads = np.abs(rho_head1 - rho_head2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(X, T, diff_heads, shading='auto', cmap='plasma')\n",
    "plt.colorbar(label='Difference')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Difference between the 2 heads')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "\n",
    "##vx\n",
    "\n",
    "# 1. Vérification des types de données\n",
    "print(f\"Type des poids du premier réseau: {next(nets[1].parameters()).dtype}\")\n",
    "\n",
    "# 2. Création du maillage\n",
    "x = np.linspace(0, 1, 100).astype(np.float32)\n",
    "t = np.linspace(0, 1, 50).astype(np.float32)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# 3. Conversion en tenseurs PyTorch\n",
    "x_tensor = torch.tensor(X.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 4. Calcul des solutions pour les deux têtes\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Vérification et conversion si nécessaire\n",
    "        if next(nets[1].parameters()).dtype != torch.float32:\n",
    "            for net in nets:\n",
    "                net.float()\n",
    "        \n",
    "        # Calcul pour les deux têtes\n",
    "        sols_head1 = solutions(x_tensor, t_tensor, head_idx=0)  # mu=0.1\n",
    "        sols_head2 = solutions(x_tensor, t_tensor, head_idx=1)  # mu=0.5\n",
    "        \n",
    "        rho_head1 = sols_head1[1].cpu().numpy().reshape(X.shape)\n",
    "        rho_head2 = sols_head2[1].cpu().numpy().reshape(X.shape)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Solution analytique\n",
    "rho_analytical1 =  x*np.exp(-T)\n",
    "rho_analytical2 =  x*x*x*np.exp(-T)\n",
    "\n",
    "# Calcul des erreurs\n",
    "error_head1 = np.abs(rho_analytical1 - rho_head1)\n",
    "error_head2 = np.abs(rho_analytical2 - rho_head2)\n",
    "\n",
    "# Création d'une figure avec 4 sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaison of vx(x,t) for the 2 heads', fontsize=16)\n",
    "\n",
    "# Graphique pour mu=0.1\n",
    "im1 = axes[0,0].pcolormesh(X, T, rho_head1, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im1, ax=axes[0,0], label='vx(x,t)')\n",
    "axes[0,0].set_title('Solution vx(x,t) - Head 1 (μ=0.1)')\n",
    "axes[0,0].set_xlabel('x')\n",
    "axes[0,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.1\n",
    "im2 = axes[0,1].pcolormesh(X, T, error_head1, shading='auto', cmap='hot')\n",
    "fig.colorbar(im2, ax=axes[0,1], label='Absolute error')\n",
    "axes[0,1].set_title('Error - Head 1 (μ=0.1)')\n",
    "axes[0,1].set_xlabel('x')\n",
    "axes[0,1].set_ylabel('t')\n",
    "\n",
    "# Graphique pour mu=0.5\n",
    "im3 = axes[1,0].pcolormesh(X, T, rho_head2, shading='auto', cmap='viridis')\n",
    "fig.colorbar(im3, ax=axes[1,0], label='vx(x,t)')\n",
    "axes[1,0].set_title('Solution vx(x,t) - Head 2 (μ=0.5)')\n",
    "axes[1,0].set_xlabel('x')\n",
    "axes[1,0].set_ylabel('t')\n",
    "\n",
    "# Erreur pour mu=0.5\n",
    "im4 = axes[1,1].pcolormesh(X, T, error_head2, shading='auto', cmap='hot')\n",
    "fig.colorbar(im4, ax=axes[1,1], label='Absolute error ')\n",
    "axes[1,1].set_title('Error - Head 2 (μ=0.5)')\n",
    "axes[1,1].set_xlabel('x')\n",
    "axes[1,1].set_ylabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs maximales pour comparaison\n",
    "print(f\"Erreur maximale tête 1 (μ=0.1): {np.max(error_head1):.3e}\")\n",
    "print(f\"Erreur maximale tête 2 (μ=0.5): {np.max(error_head2):.3e}\")\n",
    "\n",
    "# Optionnel: Différence entre les deux têtes\n",
    "diff_heads = np.abs(rho_head1 - rho_head2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(X, T, diff_heads, shading='auto', cmap='plasma')\n",
    "plt.colorbar(label='Difference')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Difference between the 2 heads')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save NN after training\n",
    "# for i, net in enumerate(nets):\n",
    "#     torch.save(net.state_dict(), f\"net_{i}.pth\")\n",
    "\n",
    "## save weights of the 5 first NN\n",
    "\n",
    "import os\n",
    "os.makedirs(\"saved_weights\", exist_ok=True)  \n",
    "\n",
    "\n",
    "for i, net in enumerate(nets[:8]):\n",
    "    torch.save(net.state_dict(), f\"saved_weights/net_{i}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur without ff\n",
    "### head 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Variables fixes :  rho(0)=2, vx=vy=vz=0  --> dérivées temporelles = 0\n",
    "    drho_dt[0] = 0.0\n",
    "    dvx_dt[0]  = 0.0\n",
    "    dvy_dt[0]  = 0.0\n",
    "    dvz_dt[0]  = 0.0\n",
    "\n",
    "    # Variables imposées = exp(-t)  -->  d/dt exp(-t) = -exp(-t)\n",
    "    bc_dot = -np.exp(-t)\n",
    "    dP_dt[0]  = bc_dot\n",
    "    dBx_dt[0] = bc_dot\n",
    "    dBy_dt[0] = bc_dot\n",
    "    dBz_dt[0] = bc_dot\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num_v1, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "\n",
    "# Grille x-t (à adapter si besoin)\n",
    "x = np.linspace(0, 1, 100).astype(np.float32)\n",
    "t = np.linspace(0, 1, 50).astype(np.float32)\n",
    "X, T = np.meshgrid(x, t, indexing='ij')  # Shape: (nx, nt)\n",
    "\n",
    "# Conversion en tenseurs torch\n",
    "x_tensor = torch.tensor(X.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN : vx est la 2e sortie, donc [1]\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=0)[1].cpu().numpy().flatten()\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(X.shape)  # (nx, nt)\n",
    "vx_num_interp = vx_num_v1  # si déjà sur la même grille\n",
    "\n",
    "\n",
    "# Interpolation de vx_num sur la grille (X, T)\n",
    "x_num = np.linspace(0, 1, vx_num.shape[0])\n",
    "t_num = np.linspace(0, 1, vx_num.shape[1])\n",
    "interp_func = RegularGridInterpolator((x_num, t_num), vx_num)\n",
    "vx_num_interp = interp_func(np.stack([X.flatten(), T.flatten()], axis=-1)).reshape(X.shape)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "error = np.abs(vx_pinn - vx_num_interp)\n",
    "\n",
    "# Affichage\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# PINN vx\n",
    "im0 = axs[0].pcolormesh(X, T, vx_pinn, shading='auto', cmap='viridis')\n",
    "axs[0].set_title('vx PINN (head 1)')\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('t')\n",
    "fig.colorbar(im0, ax=axs[0])\n",
    "\n",
    "# Solveur vx\n",
    "im1 = axs[1].pcolormesh(X, T, vx_num_interp, shading='auto', cmap='viridis')\n",
    "axs[1].set_title('vx Solveur')\n",
    "axs[1].set_xlabel('x')\n",
    "axs[1].set_ylabel('t')\n",
    "fig.colorbar(im1, ax=axs[1])\n",
    "\n",
    "# Erreur\n",
    "im2 = axs[2].pcolormesh(X, T, error, shading='auto', cmap='hot')\n",
    "axs[2].set_title('|vx PINN - vx Solveur|')\n",
    "axs[2].set_xlabel('x')\n",
    "axs[2].set_ylabel('t')\n",
    "fig.colorbar(im2, ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Info d'erreur\n",
    "print(f\"Erreur absolue max : {np.max(error):.2e}\")\n",
    "print(f\"Erreur absolue moyenne : {np.mean(error):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur without ff\n",
    "### head 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x*x*x\n",
    "    vy = x*x*x\n",
    "    vz = x*x*x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Variables fixes :  rho(0)=2, vx=vy=vz=0  --> dérivées temporelles = 0\n",
    "    drho_dt[0] = 0.0\n",
    "    dvx_dt[0]  = 0.0\n",
    "    dvy_dt[0]  = 0.0\n",
    "    dvz_dt[0]  = 0.0\n",
    "\n",
    "    # Variables imposées = exp(-t)  -->  d/dt exp(-t) = -exp(-t)\n",
    "    bc_dot = -np.exp(-t)\n",
    "    dP_dt[0]  = bc_dot\n",
    "    dBx_dt[0] = bc_dot\n",
    "    dBy_dt[0] = bc_dot\n",
    "    dBz_dt[0] = bc_dot\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v2 = sol.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg*Xg*Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v2 - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num_v2, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur without ff, with direct BC\n",
    "### head 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres\n",
    "X   = 1.0       # longueur du domaine spatial\n",
    "nx  = 300       # nombre de points spatiaux\n",
    "L   = 1.0       # durée finale\n",
    "mu  = 0.1       # viscosité\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x*x*x\n",
    "    vy = x*x*x\n",
    "    vz = x*x*x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0  = init_cond()\n",
    "sol = solve_ivp(mhd_rhs, (0, L), y0,\n",
    "                method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v2 = sol.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg  = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg*Xg*Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v2 - vx_ex\n",
    "\n",
    "# Affichage 1 : vx numérique\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vx_num_v2, extent=[0,L,0,X], aspect='auto', origin='lower')\n",
    "plt.colorbar(label='vx_num')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('vx numérique')\n",
    "\n",
    "# Affichage 2 : erreur vx_num - vx_ex\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(err, extent=[0,L,0,X], aspect='auto',\n",
    "           origin='lower', cmap='bwr', vmin=-np.max(abs(err)), vmax=np.max(abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur $v_x^{num}-x e^{-t}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1\n",
    "### works\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=0)[1].cpu().numpy().flatten() ## head 1\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "# Nouveau: Interpolation pour aligner les grilles si nécessaire\n",
    "# (Dans ce cas, les grilles sont identiques donc pas besoin d'interpolation)\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Solution du Solveur (vx numérique)')\n",
    "\n",
    "# Graphique 2: Erreur solveur vs exacte\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pcolormesh(T, Xg, err, shading='auto', cmap='bwr', \n",
    "               vmin=-np.max(np.abs(err)), vmax=np.max(np.abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur Solveur vs Solution Exacte')\n",
    "\n",
    "# Graphique 3: Prédiction PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Prédiction PINN (tête 2)')\n",
    "\n",
    "# Graphique 4: Différence Solveur-PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 4)\n",
    "diff = vx_num_v2 - vx_pinn\n",
    "plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "plt.colorbar(label='Différence')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Différence Solveur-PINN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs\n",
    "print(\"\\nAnalyse d'erreur:\")\n",
    "print(f\"Erreur max Solveur vs Exact: {np.max(np.abs(err)):.2e}\")\n",
    "print(f\"Erreur max Solveur vs PINN: {np.max(np.abs(diff)):.2e}\")\n",
    "print(f\"Erreur moyenne Solveur vs PINN: {np.mean(np.abs(diff)):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 2, vx\n",
    "### works\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "\n",
    "def forcing_terms(x, t):\n",
    "    \"\"\"\n",
    "    Retourne un tableau (8, N) avec f0..f7 sur l'espace x à l'instant t.\n",
    "    \"\"\"\n",
    "    f0 = -np.sin(x) * np.exp(-t)+x*np.cos(x)*np.exp(-2*t)+2*np.exp(-t)+np.sin(x)*np.exp(-2*t)\n",
    "    f1 = -2*x*np.exp(-t)-np.sin(x) * np.exp(-2*t)*x+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)-np.exp(-x-t)-2*np.exp(-2*x-2*t)\n",
    "    f2 = -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f3 =  -2*x*np.exp(-t)-np.sin(x) *x* np.exp(-2*t)+2*x*np.exp(-2*t)+x*np.sin(x)*np.exp(-3*t)+np.exp(-2*x-2*t)\n",
    "    f4 =  - np.exp(-x-t)+np.exp(-x-2*t)-x*np.exp(-x-2*t)\n",
    "    f5 = -np.exp(-x-t)\n",
    "    f6 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    f7 = -np.exp(-x-t)-x*np.exp(-x-2*t)\n",
    "    \n",
    "    return np.array([f0, f1, f2, f3, f4, f5, f6, f7])  # shape (8, N)\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales (ici tout est 1 sauf vx = sin(pi x))\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x*x*x\n",
    "    vy = x*x*x\n",
    "    vz = x*x*x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv2 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v2 = solv2.y[nx:2*nx, :]  # shape (nx, nt)\n",
    "T, Xg = np.meshgrid(sol.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = Xg**3 * np.exp(-T)\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v2 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=1)[1].cpu().numpy().flatten() ## head 1\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "# Nouveau: Interpolation pour aligner les grilles si nécessaire\n",
    "# (Dans ce cas, les grilles sont identiques donc pas besoin d'interpolation)\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.pcolormesh(T, Xg, vx_num_v2, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Solution du Solveur (vx numérique)')\n",
    "\n",
    "# Graphique 2: Erreur solveur vs exacte\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pcolormesh(T, Xg, err, shading='auto', cmap='bwr', \n",
    "               vmin=-np.max(np.abs(err)), vmax=np.max(np.abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur Solveur vs Solution Exacte')\n",
    "\n",
    "# Graphique 3: Prédiction PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Prédiction PINN (tête 2)')\n",
    "\n",
    "# Graphique 4: Différence Solveur-PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 4)\n",
    "diff = vx_num_v2 - vx_pinn\n",
    "plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "plt.colorbar(label='Différence')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Différence Solveur-PINN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs\n",
    "print(\"\\nAnalyse d'erreur:\")\n",
    "print(f\"Erreur max Solveur vs Exact: {np.max(np.abs(err)):.2e}\")\n",
    "print(f\"Erreur max Solveur vs PINN: {np.max(np.abs(diff)):.2e}\")\n",
    "print(f\"Erreur moyenne Solveur vs PINN: {np.mean(np.abs(diff)):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1, rho\n",
    "### works\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[0:nx, :]  # shape (nx, nt), (0:nx) pour rho\n",
    "T, Xg = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = 2\n",
    "\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=0)[0].cpu().numpy().flatten() ## head 1, rho\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "# Nouveau: Interpolation pour aligner les grilles si nécessaire\n",
    "# (Dans ce cas, les grilles sont identiques donc pas besoin d'interpolation)\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Solution du Solveur (vx numérique)')\n",
    "\n",
    "# Graphique 2: Erreur solveur vs exacte\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pcolormesh(T, Xg, err, shading='auto', cmap='bwr', \n",
    "               vmin=-np.max(np.abs(err)), vmax=np.max(np.abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur Solveur vs Solution Exacte')\n",
    "\n",
    "# Graphique 3: Prédiction PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Prédiction PINN (tête 1)')\n",
    "\n",
    "# Graphique 4: Différence Solveur-PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 4)\n",
    "diff = vx_num_v1 - vx_pinn\n",
    "plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "plt.colorbar(label='Différence')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Différence Solveur-PINN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs\n",
    "print(\"\\nAnalyse d'erreur:\")\n",
    "print(f\"Erreur max Solveur vs Exact: {np.max(np.abs(err)):.2e}\")\n",
    "print(f\"Erreur max Solveur vs PINN: {np.max(np.abs(diff)):.2e}\")\n",
    "print(f\"Erreur moyenne Solveur vs PINN: {np.mean(np.abs(diff)):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho = solv1.y[0:nx, :]           # shape (nx, nt)\n",
    "# vx  = solv1.y[nx:2*nx, :]\n",
    "# vy  = solv1.y[2*nx:3*nx, :]\n",
    "# vz  = solv1.y[3*nx:4*nx, :]\n",
    "# P   = solv1.y[4*nx:5*nx, :]\n",
    "# Bx  = solv1.y[5*nx:6*nx, :]\n",
    "# By  = solv1.y[6*nx:7*nx, :]\n",
    "# Bz  = solv1.y[7*nx:8*nx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1, vx\n",
    "### works\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "\n",
    "\n",
    "# Maillage\n",
    "x   = np.linspace(0, X, nx)\n",
    "dx  = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[5*nx:6*nx, :]  # shape (nx, nt), (0:nx) pour rho\n",
    "T, Xg = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte\n",
    "vx_ex = np.exp(-Xg)*np.exp(-T)\n",
    "# Calcul de l'erreur\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=0)[7].cpu().numpy().flatten() ## head 1, rho\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "# Nouveau: Interpolation pour aligner les grilles si nécessaire\n",
    "# (Dans ce cas, les grilles sont identiques donc pas besoin d'interpolation)\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Solution du Solveur (vx numérique)')\n",
    "\n",
    "# Graphique 2: Erreur solveur vs exacte\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pcolormesh(T, Xg, err, shading='auto', cmap='bwr', \n",
    "               vmin=-np.max(np.abs(err)), vmax=np.max(np.abs(err)))\n",
    "plt.colorbar(label='Erreur')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Erreur Solveur vs Solution Exacte')\n",
    "\n",
    "# Graphique 3: Prédiction PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "plt.colorbar(label='vx')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Prédiction PINN (tête 1)')\n",
    "\n",
    "# Graphique 4: Différence Solveur-PINN (NOUVEAU)\n",
    "plt.subplot(2, 2, 4)\n",
    "diff = vx_num_v1 - vx_pinn\n",
    "plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "plt.colorbar(label='Différence')\n",
    "plt.xlabel('Temps t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title('Différence Solveur-PINN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des erreurs\n",
    "print(\"\\nAnalyse d'erreur:\")\n",
    "print(f\"Erreur max Solveur vs Exact: {np.max(np.abs(err)):.2e}\")\n",
    "print(f\"Erreur max Solveur vs PINN: {np.max(np.abs(diff)):.2e}\")\n",
    "print(f\"Erreur moyenne Solveur vs PINN: {np.mean(np.abs(diff)):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1, vx\n",
    "### works\n",
    "## affiche parfait\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "# Maillage\n",
    "x = np.linspace(0, X, nx)\n",
    "dx = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x\n",
    "    vy = x\n",
    "    vz = x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[3*nx:4*nx, :]  # shape (nx, nt), (0:nx) pour rho\n",
    "T, Xg = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte (calculée mais non affichée)\n",
    "vx_ex = np.exp(-Xg)*np.exp(-T)\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=0)[6].cpu().numpy().flatten() ## head 1, rho\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "\n",
    "# Configuration des graphiques (3 graphiques au lieu de 4)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Paramètres de style pour agrandir le texte\n",
    "fontsize = 14  # Taille de police pour les axes et titres\n",
    "cbar_fontsize = 14  # Taille de police pour la colorbar\n",
    "title_fontsize = 16  # Taille de police pour les titres\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(1, 3, 1)\n",
    "img1 = plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "cbar1 = plt.colorbar(img1)\n",
    "cbar1.set_label('vz', fontsize=cbar_fontsize)\n",
    "cbar1.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver solution', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 2: Prédiction PINN\n",
    "plt.subplot(1, 3, 2)\n",
    "img2 = plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "cbar2 = plt.colorbar(img2)\n",
    "cbar2.set_label('vz', fontsize=cbar_fontsize)\n",
    "cbar2.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('PINN prediction(head 1)', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 3: Différence Solveur-PINN\n",
    "plt.subplot(1, 3, 3)\n",
    "diff = vx_num_v1 - vx_pinn\n",
    "img3 = plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "cbar3 = plt.colorbar(img3)\n",
    "cbar3.set_label('Difference', fontsize=cbar_fontsize)\n",
    "cbar3.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver-PINN difference', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TL on CIs (new head head3 initialized on head2)\n",
    "## without ff, with BC\n",
    "\n",
    "from neurodiffeq.operators import diff  # Import crucial pour les dérivées\n",
    "\n",
    "\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées (inchangées)\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Têtes existantes (head1, head2) + nouvelle tête (head3)\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head3 = nn.Linear(hidden_units[1], n_output_units)  # Nouvelle tête pour nouvelles CI\n",
    "\n",
    "    def forward(self, x, head_idx=2):  # head_idx=2 par défaut (head3)\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        elif head_idx == 1:\n",
    "            return self.head2(shared)\n",
    "        else:\n",
    "            return self.head3(shared)\n",
    "\n",
    "\n",
    "## Initialisation des réseaux pour le transfer learning\n",
    "nets = []\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "bc_losses = []  # Pour suivre la loss des conditions aux limites\n",
    "\n",
    "## Nouvelle condition initiale pour head3\n",
    "new_initial_conditions = {\n",
    "    'rho': lambda x: 2*torch.ones_like(x),\n",
    "    'v': lambda x: x*x,\n",
    "    'P': lambda x: torch.exp(-x),\n",
    "    'By': lambda x: torch.exp(-x),\n",
    "    'Bz': lambda x: torch.exp(-x),\n",
    "    'vy': lambda x: x*x,\n",
    "    'vz': lambda x: x*x,\n",
    "    'Bx': lambda x: torch.exp(-x)\n",
    "}\n",
    "\n",
    "## Conditions aux limites\n",
    "def boundary_conditions(t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(t),\n",
    "        'v': torch.zeros_like(t),\n",
    "        'vy': torch.zeros_like(t),\n",
    "        'vz': torch.zeros_like(t),\n",
    "        'P': torch.exp(-t),\n",
    "        'Bx': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t)\n",
    "    }\n",
    "\n",
    "## Chargement des poids pré-entraînés\n",
    "for i in range(8):\n",
    "    net = MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256])\n",
    "    \n",
    "    # Charger les poids existants\n",
    "    pretrained_dict = torch.load(f\"saved_weights/net_{i}.pt\", map_location='cpu')\n",
    "    model_dict = net.state_dict()\n",
    "    \n",
    "    # Copier les couches partagées + head1 + head2\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    # Initialiser head3 avec head2\n",
    "    for name, param in pretrained_dict.items():\n",
    "        if name.startswith(\"head2.\"):\n",
    "            corresponding_name = name.replace(\"head2.\", \"head3.\")\n",
    "            if corresponding_name in model_dict:\n",
    "                model_dict[corresponding_name] = param.clone()\n",
    "\n",
    "    net.load_state_dict(model_dict, strict=False)\n",
    "    nets.append(net)\n",
    "\n",
    "## Seul head3 est entraînable\n",
    "for net in nets:\n",
    "    for name, param in net.named_parameters():\n",
    "        param.requires_grad = ('head3' in name)\n",
    "\n",
    "## Optimiseur\n",
    "optimizer = optim.Adam([p for net in nets for p in net.parameters() if p.requires_grad], lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.975)\n",
    "\n",
    "## PDE system sans forçage\n",
    "def pde_systemTL(rho, vx, P, By, Bz, vy, vz, Bx, x, t):\n",
    "    # Convertir les entrées en tensors si nécessaire\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32, requires_grad=True)\n",
    "    if not isinstance(t, torch.Tensor):\n",
    "        t = torch.tensor(t, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    # Assurer que toutes les variables sont des tensors avec grad\n",
    "    variables = [rho, vx, P, By, Bz, vy, vz, Bx]\n",
    "    for i, var in enumerate(variables):\n",
    "        if not isinstance(var, torch.Tensor):\n",
    "            variables[i] = torch.tensor(var, dtype=torch.float32, requires_grad=True)\n",
    "    rho, vx, P, By, Bz, vy, vz, Bx = variables\n",
    "    \n",
    "    # Calcul des équations PDE\n",
    "    eq1 = diff(rho, t) + vx * diff(rho, x) + rho * diff(vx, x)\n",
    "    eq2 = rho * diff(vx, t) + rho * vx * diff(vx, x) + diff(P, x) + By * diff(By, x) + Bz * diff(Bz, x) - rho * mu * diff(vx, x, order=2)\n",
    "    eq3 = rho * diff(vy, t) + rho * vx * diff(vy, x) - Bx * diff(By, x)\n",
    "    eq4 = rho * diff(vz, t) + rho * vx * diff(vz, x) - Bx * diff(Bz, x)\n",
    "    eq5 = diff(P, t) + P * diff(vx, x) + vx * diff(P, x)\n",
    "    eq6 = diff(Bx, t)\n",
    "    eq7 = diff(By, t) + vx * diff(By, x) + By * diff(vx, x) - Bx * diff(vy, x)\n",
    "    eq8 = diff(Bz, t) + vx * diff(Bz, x) + Bz * diff(vx, x) - Bx * diff(vz, x)\n",
    "    \n",
    "    return [eq1, eq2, eq3, eq4, eq5, eq6, eq7, eq8]\n",
    "\n",
    "\n",
    "## Entraînement\n",
    "n_epochs = 12000\n",
    "print_interval = n_epochs // 10  # Afficher tous les 10% de progression\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 1. PDE Loss\n",
    "    samples = train_gen.get_examples()\n",
    "    x_train = samples[0].view(-1, 1)\n",
    "    t_train = samples[1].view(-1, 1)\n",
    "    inputs = torch.cat((x_train, t_train), dim=1)\n",
    "    \n",
    "    outputs = [net(inputs, head_idx=2) for net in nets]  # Utilisation de head3\n",
    "    \n",
    "    pde_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "    loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in pde_residuals])\n",
    "    \n",
    "    # 2. Initial condition loss\n",
    "    ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "    ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "    ic_targets = [new_initial_conditions[key](ic_x) for key in ['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx']]\n",
    "    loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "    \n",
    "    # 3. Boundary condition loss (x=0)\n",
    "    bc_samples = bc_gen.get_examples()\n",
    "    x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1)  # x=0\n",
    "    t_bc = bc_samples[1].view(-1, 1)\n",
    "    bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "    \n",
    "    bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "    bc_targets = boundary_conditions(t_bc)\n",
    "    loss_bc = sum([\n",
    "        criterion(bc_outputs[0], bc_targets['rho']),\n",
    "        criterion(bc_outputs[1], bc_targets['v']),\n",
    "        criterion(bc_outputs[2], bc_targets['P']),\n",
    "        criterion(bc_outputs[3], bc_targets['By']),\n",
    "        criterion(bc_outputs[4], bc_targets['Bz']),\n",
    "        criterion(bc_outputs[5], bc_targets['vy']),\n",
    "        criterion(bc_outputs[6], bc_targets['vz']),\n",
    "        criterion(bc_outputs[7], bc_targets['Bx'])\n",
    "    ])\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = loss_pde + loss_ic + loss_bc\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "   \n",
    "    # Afficher seulement tous les 10% de progression\n",
    "    if (epoch + 1) % print_interval == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} ({100*(epoch+1)/n_epochs:.0f}%) | \"\n",
    "              f\"PDE: {loss_pde.item():.3e} | \"\n",
    "              f\"IC: {loss_ic.item():.3e} | \"\n",
    "              f\"BC: {loss_bc.item():.3e} | \"\n",
    "              f\"Total: {total_loss.item():.3e}\")\n",
    "    \n",
    "    total_losses.append(total_loss.item())\n",
    "    pde_losses.append(loss_pde.item())\n",
    "    ic_losses.append(loss_ic.item())\n",
    "    bc_losses.append(loss_bc.item())\n",
    "\n",
    "# Pour évaluation\n",
    "def solutions_new_ci(x, t):\n",
    "    return [net(torch.cat((x, t), dim=1), head_idx=2).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(total_losses, label='Total Loss')\n",
    "plt.semilogy(pde_losses, label='PDE Loss', linestyle='--')\n",
    "plt.semilogy(ic_losses, label='IC Loss', linestyle=':')\n",
    "plt.semilogy(bc_losses, label='BC Loss', linestyle=':')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Training Loss Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1, rho\n",
    "### works\n",
    "## \n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "# Maillage\n",
    "x = np.linspace(0, X, nx)\n",
    "dx = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x*x\n",
    "    vy = x*x\n",
    "    vz = x*x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[7*nx:8*nx, :]  # shape (nx, nt), (0:nx) pour rho\n",
    "T, Xg = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte (calculée mais non affichée)\n",
    "vx_ex = np.exp(-Xg)*np.exp(-T)\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=2)[4].cpu().numpy().flatten() ## head 1, rho\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "\n",
    "# Configuration des graphiques (3 graphiques au lieu de 4)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Paramètres de style pour agrandir le texte\n",
    "fontsize = 14  # Taille de police pour les axes et titres\n",
    "cbar_fontsize = 14  # Taille de police pour la colorbar\n",
    "title_fontsize = 16  # Taille de police pour les titres\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(1, 3, 1)\n",
    "img1 = plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "cbar1 = plt.colorbar(img1)\n",
    "cbar1.set_label('Bz', fontsize=cbar_fontsize)\n",
    "cbar1.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver solution', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 2: Prédiction PINN\n",
    "plt.subplot(1, 3, 2)\n",
    "img2 = plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "cbar2 = plt.colorbar(img2)\n",
    "cbar2.set_label('Bz', fontsize=cbar_fontsize)\n",
    "cbar2.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('PINN prediction (with transfer learning)', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 3: Différence Solveur-PINN\n",
    "plt.subplot(1, 3, 3)\n",
    "diff = vx_num_v1 - vx_pinn\n",
    "img3 = plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "cbar3 = plt.colorbar(img3)\n",
    "cbar3.set_label('Difference', fontsize=cbar_fontsize)\n",
    "cbar3.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver-PINN difference', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L-BFGS\n",
    "# TL sur les CI (nouvelle tête head3 initialisée sur head2)\n",
    "## without ff, with BC\n",
    "## doesn't work\n",
    "\n",
    "from neurodiffeq.operators import diff  # Import crucial pour les dérivées\n",
    "\n",
    "\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées (inchangées)\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Têtes existantes (head1, head2) + nouvelle tête (head3)\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head3 = nn.Linear(hidden_units[1], n_output_units)  # Nouvelle tête pour nouvelles CI\n",
    "\n",
    "    def forward(self, x, head_idx=2):  # head_idx=2 par défaut (head3)\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        elif head_idx == 1:\n",
    "            return self.head2(shared)\n",
    "        else:\n",
    "            return self.head3(shared)\n",
    "\n",
    "\n",
    "## Initialisation des réseaux pour le transfer learning\n",
    "nets = []\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "bc_losses = []  # Pour suivre la loss des conditions aux limites\n",
    "\n",
    "## Nouvelle condition initiale pour head3\n",
    "new_initial_conditions = {\n",
    "    'rho': lambda x: 2*torch.ones_like(x),\n",
    "    'v': lambda x: x*x,\n",
    "    'P': lambda x: torch.exp(-x),\n",
    "    'By': lambda x: torch.exp(-x),\n",
    "    'Bz': lambda x: torch.exp(-x),\n",
    "    'vy': lambda x: x*x,\n",
    "    'vz': lambda x: x*x,\n",
    "    'Bx': lambda x: torch.exp(-x)\n",
    "}\n",
    "\n",
    "## Conditions aux limites\n",
    "def boundary_conditions(t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(t),\n",
    "        'v': torch.zeros_like(t),\n",
    "        'vy': torch.zeros_like(t),\n",
    "        'vz': torch.zeros_like(t),\n",
    "        'P': torch.exp(-t),\n",
    "        'Bx': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t)\n",
    "    }\n",
    "\n",
    "## Chargement des poids pré-entraînés\n",
    "for i in range(8):\n",
    "    net = MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256])\n",
    "    \n",
    "    # Charger les poids existants\n",
    "    pretrained_dict = torch.load(f\"saved_weights/net_{i}.pt\", map_location='cpu')\n",
    "    model_dict = net.state_dict()\n",
    "    \n",
    "    # Copier les couches partagées + head1 + head2\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    # Initialiser head3 avec head2\n",
    "    for name, param in pretrained_dict.items():\n",
    "        if name.startswith(\"head2.\"):\n",
    "            corresponding_name = name.replace(\"head2.\", \"head3.\")\n",
    "            if corresponding_name in model_dict:\n",
    "                model_dict[corresponding_name] = param.clone()\n",
    "\n",
    "    net.load_state_dict(model_dict, strict=False)\n",
    "    nets.append(net)\n",
    "\n",
    "## Seul head3 est entraînable\n",
    "for net in nets:\n",
    "    for name, param in net.named_parameters():\n",
    "        param.requires_grad = ('head3' in name)\n",
    "\n",
    "## Optimiseur\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "    [p for net in nets for p in net.parameters() if p.requires_grad],\n",
    "    lr=0.01,              # Réduire pour plus de stabilité\n",
    "    max_iter=10, \n",
    "    history_size=50,          # Éviter les sur-optimisations\n",
    "    line_search_fn=None    # Désactiver si instable\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.975)\n",
    "\n",
    "## PDE system sans forçage\n",
    "def pde_systemTL(rho, vx, P, By, Bz, vy, vz, Bx, x, t):\n",
    "    # Aucun .detach() ici - tous les tenseurs doivent être différentiables\n",
    "    eq1 = diff(rho, t) + vx * diff(rho, x) + rho * diff(vx, x)\n",
    "    eq2 = rho * diff(vx, t) + rho * vx * diff(vx, x) + diff(P, x) + By * diff(By, x) + Bz * diff(Bz, x) - rho * mu * diff(vx, x, order=2)\n",
    "    eq3 = rho * diff(vy, t) + rho * vx * diff(vy, x) - Bx * diff(By, x)\n",
    "    eq4 = rho * diff(vz, t) + rho * vx * diff(vz, x) - Bx * diff(Bz, x)\n",
    "    eq5 = diff(P, t) + P * diff(vx, x) + vx * diff(P, x)\n",
    "    eq6 = diff(Bx, t)\n",
    "    eq7 = diff(By, t) + vx * diff(By, x) + By * diff(vx, x) - Bx * diff(vy, x)\n",
    "    eq8 = diff(Bz, t) + vx * diff(Bz, x) + Bz * diff(vx, x) - Bx * diff(vz, x)\n",
    "    \n",
    "    return [eq1, eq2, eq3, eq4, eq5, eq6, eq7, eq8]\n",
    "\n",
    "\n",
    "## Entraînement\n",
    "n_epochs = 150\n",
    "print_interval = n_epochs // 10  # Afficher tous les 10% de progression\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Régénération des données À L'INTÉRIEUR de la closure\n",
    "    samples = train_gen.get_examples()\n",
    "    x_train = samples[0].view(-1, 1).requires_grad_(True)\n",
    "    t_train = samples[1].view(-1, 1).requires_grad_(True)\n",
    "    inputs = torch.cat((x_train, t_train), dim=1)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = []\n",
    "    for net in nets:\n",
    "        out = net(inputs, head_idx=2)\n",
    "        if not out.requires_grad:\n",
    "            out = out.clone().detach().requires_grad_(True)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Calcul des résidus PDE\n",
    "    train_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "    loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in train_residuals])\n",
    "\n",
    "    # Calcul des autres losses\n",
    "    ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "    ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "    ic_targets = [new_initial_conditions[key](ic_x) for key in ['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx']]\n",
    "    loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "    \n",
    "    bc_samples = bc_gen.get_examples()\n",
    "    x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1).requires_grad_(True)\n",
    "    t_bc = bc_samples[1].view(-1, 1).requires_grad_(True)\n",
    "    bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "    bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "    bc_targets = boundary_conditions(t_bc)\n",
    "    loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                  for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])])\n",
    "    \n",
    "    total_loss = loss_pde + loss_ic + loss_bc\n",
    "    total_loss.backward()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    # L-BFGS step\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # Affichage périodique\n",
    "    if (epoch + 1) % print_interval == 0 or epoch == 0:\n",
    "        # On doit garder les gradients pour le calcul des résidus PDE\n",
    "        with torch.enable_grad():  # <-- Changement crucial ici\n",
    "            samples = train_gen.get_examples()\n",
    "            x_train = samples[0].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            t_train = samples[1].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            inputs = torch.cat((x_train, t_train), dim=1)\n",
    "            \n",
    "            outputs = [net(inputs, head_idx=2) for net in nets]\n",
    "            pde_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "            \n",
    "            # Calcul des losses avec no_grad pour juste l'évaluation\n",
    "            with torch.no_grad():\n",
    "                loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in pde_residuals]).item()\n",
    "                ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "                loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)]).item()\n",
    "                \n",
    "                bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "                loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                             for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])]).item()\n",
    "                \n",
    "                total_loss = loss_pde + loss_ic + loss_bc\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} ({100*(epoch+1)/n_epochs:.0f}%) | \"\n",
    "                      f\"PDE: {loss_pde:.3e} | \"\n",
    "                      f\"IC: {loss_ic:.3e} | \"\n",
    "                      f\"BC: {loss_bc:.3e} | \"\n",
    "                      f\"Total: {total_loss:.3e}\")\n",
    "                \n",
    "                print(\"Résidus:\", [r.mean().item() for r in pde_residuals])\n",
    "        \n",
    "        # Enregistrement des losses\n",
    "        total_losses.append(total_loss)\n",
    "        pde_losses.append(loss_pde)\n",
    "        ic_losses.append(loss_ic)\n",
    "        bc_losses.append(loss_bc)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Pour évaluation\n",
    "def solutions_new_ci(x, t):\n",
    "    return [net(torch.cat((x, t), dim=1), head_idx=2).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L-BFGS method !\n",
    "# TL on CI (new head : head3 initialized on head2)\n",
    "## without ff, with BC\n",
    "\n",
    "from neurodiffeq.operators import diff  # Import crucial pour les dérivées\n",
    "\n",
    "\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées (inchangées)\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Têtes existantes (head1, head2) + nouvelle tête (head3)\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head3 = nn.Linear(hidden_units[1], n_output_units)  # Nouvelle tête pour nouvelles CI\n",
    "\n",
    "    def forward(self, x, head_idx=2):  # head_idx=2 par défaut (head3)\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        elif head_idx == 1:\n",
    "            return self.head2(shared)\n",
    "        else:\n",
    "            return self.head3(shared)\n",
    "\n",
    "\n",
    "## Initialisation des réseaux pour le transfer learning\n",
    "nets = []\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "bc_losses = []  # Pour suivre la loss des conditions aux limites\n",
    "\n",
    "## Nouvelle condition initiale pour head3\n",
    "new_initial_conditions = {\n",
    "    'rho': lambda x: 2*torch.ones_like(x),\n",
    "    'v': lambda x: x*x,\n",
    "    'P': lambda x: torch.exp(-x),\n",
    "    'By': lambda x: torch.exp(-x),\n",
    "    'Bz': lambda x: torch.exp(-x),\n",
    "    'vy': lambda x: x*x,\n",
    "    'vz': lambda x: x*x,\n",
    "    'Bx': lambda x: torch.exp(-x)\n",
    "}\n",
    "\n",
    "## Conditions aux limites\n",
    "def boundary_conditions(t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(t),\n",
    "        'v': torch.zeros_like(t),\n",
    "        'vy': torch.zeros_like(t),\n",
    "        'vz': torch.zeros_like(t),\n",
    "        'P': torch.exp(-t),\n",
    "        'Bx': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t)\n",
    "    }\n",
    "\n",
    "## Chargement des poids pré-entraînés\n",
    "for i in range(8):\n",
    "    net = MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256])\n",
    "    \n",
    "    # Charger les poids existants\n",
    "    pretrained_dict = torch.load(f\"saved_weights/net_{i}.pt\", map_location='cpu')\n",
    "    model_dict = net.state_dict()\n",
    "    \n",
    "    # Copier les couches partagées + head1 + head2\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    # Initialiser head3 avec head2\n",
    "    for name, param in pretrained_dict.items():\n",
    "        if name.startswith(\"head2.\"):\n",
    "            corresponding_name = name.replace(\"head2.\", \"head3.\")\n",
    "            if corresponding_name in model_dict:\n",
    "                model_dict[corresponding_name] = param.clone()\n",
    "\n",
    "    net.load_state_dict(model_dict, strict=False)\n",
    "    nets.append(net)\n",
    "\n",
    "## Seul head3 est entraînable\n",
    "for net in nets:\n",
    "    for name, param in net.named_parameters():\n",
    "        param.requires_grad = ('head3' in name)\n",
    "\n",
    "## Optimiseur\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "    [p for net in nets for p in net.parameters() if p.requires_grad],\n",
    "    lr=0.01,              # Réduire pour plus de stabilité\n",
    "    max_iter=10, \n",
    "    history_size=50,          # Éviter les sur-optimisations\n",
    "    line_search_fn=None    # Désactiver si instable\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.975)\n",
    "\n",
    "## PDE system sans forçage\n",
    "def pde_systemTL(rho, vx, P, By, Bz, vy, vz, Bx, x, t):\n",
    "    # Aucun .detach() ici - tous les tenseurs doivent être différentiables\n",
    "    eq1 = diff(rho, t) + vx * diff(rho, x) + rho * diff(vx, x)\n",
    "    eq2 = rho * diff(vx, t) + rho * vx * diff(vx, x) + diff(P, x) + By * diff(By, x) + Bz * diff(Bz, x) - rho * mu * diff(vx, x, order=2)\n",
    "    eq3 = rho * diff(vy, t) + rho * vx * diff(vy, x) - Bx * diff(By, x)\n",
    "    eq4 = rho * diff(vz, t) + rho * vx * diff(vz, x) - Bx * diff(Bz, x)\n",
    "    eq5 = diff(P, t) + P * diff(vx, x) + vx * diff(P, x)\n",
    "    eq6 = diff(Bx, t)\n",
    "    eq7 = diff(By, t) + vx * diff(By, x) + By * diff(vx, x) - Bx * diff(vy, x)\n",
    "    eq8 = diff(Bz, t) + vx * diff(Bz, x) + Bz * diff(vx, x) - Bx * diff(vz, x)\n",
    "    \n",
    "    return [eq1, eq2, eq3, eq4, eq5, eq6, eq7, eq8]\n",
    "\n",
    "\n",
    "## Entraînement\n",
    "n_epochs = 150\n",
    "print_interval = n_epochs // 10  # Afficher tous les 10% de progression\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Régénération des données À L'INTÉRIEUR de la closure\n",
    "    samples = train_gen.get_examples()\n",
    "    x_train = samples[0].view(-1, 1).requires_grad_(True)\n",
    "    t_train = samples[1].view(-1, 1).requires_grad_(True)\n",
    "    inputs = torch.cat((x_train, t_train), dim=1)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = []\n",
    "    for net in nets:\n",
    "        out = net(inputs, head_idx=2)\n",
    "        if not out.requires_grad:\n",
    "            out = out.clone().detach().requires_grad_(True)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Calcul des résidus PDE\n",
    "    train_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "    loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in train_residuals])\n",
    "\n",
    "    # Calcul des autres losses\n",
    "    ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "    ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "    ic_targets = [new_initial_conditions[key](ic_x) for key in ['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx']]\n",
    "    loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "    \n",
    "    bc_samples = bc_gen.get_examples()\n",
    "    x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1).requires_grad_(True)\n",
    "    t_bc = bc_samples[1].view(-1, 1).requires_grad_(True)\n",
    "    bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "    bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "    bc_targets = boundary_conditions(t_bc)\n",
    "    loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                  for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])])\n",
    "    \n",
    "    total_loss = loss_pde + loss_ic + loss_bc\n",
    "    total_loss.backward()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    # L-BFGS step\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # Affichage périodique\n",
    "    if (epoch + 1) % print_interval == 0 or epoch == 0:\n",
    "        # On doit garder les gradients pour le calcul des résidus PDE\n",
    "        with torch.enable_grad():  # <-- Changement crucial ici\n",
    "            samples = train_gen.get_examples()\n",
    "            x_train = samples[0].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            t_train = samples[1].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            inputs = torch.cat((x_train, t_train), dim=1)\n",
    "            \n",
    "            outputs = [net(inputs, head_idx=2) for net in nets]\n",
    "            pde_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "            \n",
    "            # Calcul des losses avec no_grad pour juste l'évaluation\n",
    "            with torch.no_grad():\n",
    "                loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in pde_residuals]).item()\n",
    "                ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "                loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)]).item()\n",
    "                \n",
    "                bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "                loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                             for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])]).item()\n",
    "                \n",
    "                total_loss = loss_pde + loss_ic + loss_bc\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} ({100*(epoch+1)/n_epochs:.0f}%) | \"\n",
    "                      f\"PDE: {loss_pde:.3e} | \"\n",
    "                      f\"IC: {loss_ic:.3e} | \"\n",
    "                      f\"BC: {loss_bc:.3e} | \"\n",
    "                      f\"Total: {total_loss:.3e}\")\n",
    "                \n",
    "                print(\"Résidus:\", [r.mean().item() for r in pde_residuals])\n",
    "       \n",
    "        \n",
    "        # Enregistrement des losses\n",
    "        total_losses.append(total_loss)\n",
    "        pde_losses.append(loss_pde)\n",
    "        ic_losses.append(loss_ic)\n",
    "        bc_losses.append(loss_bc)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Pour évaluation\n",
    "def solutions_new_ci(x, t):\n",
    "    return [net(torch.cat((x, t), dim=1), head_idx=2).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL on the CI (new head : head3 initialized on head2)\n",
    "## without ff, with BC\n",
    "## works !\n",
    "## L-BFGS method\n",
    "\n",
    "from neurodiffeq.operators import diff  # Import crucial pour les dérivées\n",
    "\n",
    "\n",
    "class MultiHeadFCNN(nn.Module):\n",
    "    def __init__(self, n_input_units=2, n_output_units=1, hidden_units=[256, 256]):\n",
    "        super().__init__()\n",
    "        # Couches partagées (inchangées)\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(n_input_units, hidden_units[0]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Têtes existantes (head1, head2) + nouvelle tête (head3)\n",
    "        self.head1 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head2 = nn.Linear(hidden_units[1], n_output_units)\n",
    "        self.head3 = nn.Linear(hidden_units[1], n_output_units)  # Nouvelle tête pour nouvelles CI\n",
    "\n",
    "    def forward(self, x, head_idx=2):  # head_idx=2 par défaut (head3)\n",
    "        shared = self.shared_layers(x)\n",
    "        if head_idx == 0:\n",
    "            return self.head1(shared)\n",
    "        elif head_idx == 1:\n",
    "            return self.head2(shared)\n",
    "        else:\n",
    "            return self.head3(shared)\n",
    "\n",
    "\n",
    "## Initialisation des réseaux pour le transfer learning\n",
    "nets = []\n",
    "total_losses = []\n",
    "pde_losses = []\n",
    "ic_losses = []\n",
    "bc_losses = []  # Pour suivre la loss des conditions aux limites\n",
    "\n",
    "## Nouvelle condition initiale pour head3\n",
    "new_initial_conditions = {\n",
    "    'rho': lambda x: 2*torch.ones_like(x),\n",
    "    'v': lambda x: x*x,\n",
    "    'P': lambda x: torch.exp(-x),\n",
    "    'By': lambda x: torch.exp(-x),\n",
    "    'Bz': lambda x: torch.exp(-x),\n",
    "    'vy': lambda x: x*x,\n",
    "    'vz': lambda x: x*x,\n",
    "    'Bx': lambda x: torch.exp(-x)\n",
    "}\n",
    "\n",
    "## Conditions aux limites\n",
    "def boundary_conditions(t):\n",
    "    \"\"\"Retourne les valeurs cibles pour x=0\"\"\"\n",
    "    return {\n",
    "        'rho': 2.0 * torch.ones_like(t),\n",
    "        'v': torch.zeros_like(t),\n",
    "        'vy': torch.zeros_like(t),\n",
    "        'vz': torch.zeros_like(t),\n",
    "        'P': torch.exp(-t),\n",
    "        'Bx': torch.exp(-t),\n",
    "        'By': torch.exp(-t),\n",
    "        'Bz': torch.exp(-t)\n",
    "    }\n",
    "\n",
    "## Chargement des poids pré-entraînés\n",
    "for i in range(8):\n",
    "    net = MultiHeadFCNN(n_input_units=2, n_output_units=1, hidden_units=[256, 256])\n",
    "    \n",
    "    # Charger les poids existants\n",
    "    pretrained_dict = torch.load(f\"saved_weights/net_{i}.pt\", map_location='cpu')\n",
    "    model_dict = net.state_dict()\n",
    "    \n",
    "    # Copier les couches partagées + head1 + head2\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    # Initialiser head3 avec head2\n",
    "    for name, param in pretrained_dict.items():\n",
    "        if name.startswith(\"head2.\"):\n",
    "            corresponding_name = name.replace(\"head2.\", \"head3.\")\n",
    "            if corresponding_name in model_dict:\n",
    "                model_dict[corresponding_name] = param.clone()\n",
    "\n",
    "    net.load_state_dict(model_dict, strict=False)\n",
    "    nets.append(net)\n",
    "\n",
    "## Seul head3 est entraînable\n",
    "for net in nets:\n",
    "    for name, param in net.named_parameters():\n",
    "        param.requires_grad = ('head3' in name)\n",
    "\n",
    "## Optimiseur\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "    [p for net in nets for p in net.parameters() if p.requires_grad],\n",
    "    lr=0.01,              # Réduire pour plus de stabilité\n",
    "    max_iter=10, \n",
    "    history_size=50,          # Éviter les sur-optimisations\n",
    "    line_search_fn='strong_wolfe'    # None à désactiver si instable\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.975)\n",
    "\n",
    "## PDE system sans forçage\n",
    "def pde_systemTL(rho, vx, P, By, Bz, vy, vz, Bx, x, t):\n",
    "    # Aucun .detach() ici - tous les tenseurs doivent être différentiables\n",
    "    eq1 = diff(rho, t) + vx * diff(rho, x) + rho * diff(vx, x)\n",
    "    eq2 = rho * diff(vx, t) + rho * vx * diff(vx, x) + diff(P, x) + By * diff(By, x) + Bz * diff(Bz, x) - rho * mu * diff(vx, x, order=2)\n",
    "    eq3 = rho * diff(vy, t) + rho * vx * diff(vy, x) - Bx * diff(By, x)\n",
    "    eq4 = rho * diff(vz, t) + rho * vx * diff(vz, x) - Bx * diff(Bz, x)\n",
    "    eq5 = diff(P, t) + P * diff(vx, x) + vx * diff(P, x)\n",
    "    eq6 = diff(Bx, t)\n",
    "    eq7 = diff(By, t) + vx * diff(By, x) + By * diff(vx, x) - Bx * diff(vy, x)\n",
    "    eq8 = diff(Bz, t) + vx * diff(Bz, x) + Bz * diff(vx, x) - Bx * diff(vz, x)\n",
    "    \n",
    "    return [eq1, eq2, eq3, eq4, eq5, eq6, eq7, eq8]\n",
    "\n",
    "\n",
    "## Entraînement\n",
    "n_epochs = 150\n",
    "print_interval = n_epochs // 10  # Afficher tous les 10% de progression\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Régénération des données À L'INTÉRIEUR de la closure\n",
    "    samples = train_gen.get_examples()\n",
    "    x_train = samples[0].view(-1, 1).requires_grad_(True)\n",
    "    t_train = samples[1].view(-1, 1).requires_grad_(True)\n",
    "    inputs = torch.cat((x_train, t_train), dim=1)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = []\n",
    "    for net in nets:\n",
    "        out = net(inputs, head_idx=2)\n",
    "        if not out.requires_grad:\n",
    "            out = out.clone().detach().requires_grad_(True)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Calcul des résidus PDE\n",
    "    train_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "    loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in train_residuals])\n",
    "\n",
    "    # Calcul des autres losses\n",
    "    ic_inputs = torch.cat((ic_x, ic_t), dim=1)\n",
    "    ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "    ic_targets = [new_initial_conditions[key](ic_x) for key in ['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx']]\n",
    "    loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)])\n",
    "    \n",
    "    bc_samples = bc_gen.get_examples()\n",
    "    x_bc = torch.zeros_like(bc_samples[0]).view(-1, 1).requires_grad_(True)\n",
    "    t_bc = bc_samples[1].view(-1, 1).requires_grad_(True)\n",
    "    bc_inputs = torch.cat((x_bc, t_bc), dim=1)\n",
    "    bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "    bc_targets = boundary_conditions(t_bc)\n",
    "    loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                  for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])])\n",
    "    \n",
    "    total_loss = loss_pde + loss_ic + loss_bc\n",
    "    total_loss.backward()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    # L-BFGS step\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # Affichage périodique\n",
    "    if (epoch + 1) % print_interval == 0 or epoch == 0:\n",
    "        # On doit garder les gradients pour le calcul des résidus PDE\n",
    "        with torch.enable_grad():  # <-- Changement crucial ici\n",
    "            samples = train_gen.get_examples()\n",
    "            x_train = samples[0].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            t_train = samples[1].view(-1, 1).requires_grad_(True)  # <-- Ajout requires_grad\n",
    "            inputs = torch.cat((x_train, t_train), dim=1)\n",
    "            \n",
    "            outputs = [net(inputs, head_idx=2) for net in nets]\n",
    "            pde_residuals = pde_systemTL(*outputs, x_train, t_train)\n",
    "            \n",
    "            # Calcul des losses avec no_grad pour juste l'évaluation\n",
    "            with torch.no_grad():\n",
    "                loss_pde = sum([criterion(res, torch.zeros_like(res)) for res in pde_residuals]).item()\n",
    "                ic_outputs = [net(ic_inputs, head_idx=2) for net in nets]\n",
    "                loss_ic = sum([criterion(out, target) for out, target in zip(ic_outputs, ic_targets)]).item()\n",
    "                \n",
    "                bc_outputs = [net(bc_inputs, head_idx=2) for net in nets]\n",
    "                loss_bc = sum([criterion(bc_outputs[i], bc_targets[key]) \n",
    "                             for i, key in enumerate(['rho', 'v', 'P', 'By', 'Bz', 'vy', 'vz', 'Bx'])]).item()\n",
    "                \n",
    "                total_loss = loss_pde + loss_ic + loss_bc\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} ({100*(epoch+1)/n_epochs:.0f}%) | \"\n",
    "                      f\"PDE: {loss_pde:.3e} | \"\n",
    "                      f\"IC: {loss_ic:.3e} | \"\n",
    "                      f\"BC: {loss_bc:.3e} | \"\n",
    "                      f\"Total: {total_loss:.3e}\")\n",
    "                \n",
    "                print(\"Résidus:\", [r.mean().item() for r in pde_residuals])\n",
    "        \n",
    "        # Enregistrement des losses\n",
    "        total_losses.append(total_loss)\n",
    "        pde_losses.append(loss_pde)\n",
    "        ic_losses.append(loss_ic)\n",
    "        bc_losses.append(loss_bc)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Pour évaluation\n",
    "def solutions_new_ci(x, t):\n",
    "    return [net(torch.cat((x, t), dim=1), head_idx=2).detach() for net in nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss correct\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Création des abscisses correctes (de 1 à 150)\n",
    "epochs = np.linspace(1, 150, len(total_losses))  # Adapte l'échelle\n",
    "\n",
    "plt.semilogy(epochs, total_losses, label='Total Loss')\n",
    "plt.semilogy(epochs, pde_losses, label='PDE Loss', linestyle='--')\n",
    "plt.semilogy(epochs, ic_losses, label='IC Loss', linestyle=':')\n",
    "plt.semilogy(epochs, bc_losses, label='BC Loss', linestyle=':')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Training Loss Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.xticks(np.arange(0, 151, 25))  # Graduations tous les 15 epochs\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### solveur and PINN head 1\n",
    "### works\n",
    "## L-BFGS method\n",
    "## output must be adapted to your need\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Paramètres\n",
    "X = 1.0       # longueur du domaine spatial\n",
    "nx = 300      # nombre de points spatiaux\n",
    "L = 1.0       # durée finale\n",
    "mu = 0.1      # viscosité\n",
    "\n",
    "# Maillage\n",
    "x = np.linspace(0, X, nx)\n",
    "dx = x[1] - x[0]\n",
    "t_eval = np.linspace(0, L, nx)\n",
    "\n",
    "# Conditions initiales\n",
    "def init_cond():\n",
    "    rho = 2*np.ones_like(x)\n",
    "    vx = x*x\n",
    "    vy = x*x\n",
    "    vz = x*x\n",
    "    P = np.exp(-x)\n",
    "    Bx = np.exp(-x)\n",
    "    By = np.exp(-x)\n",
    "    Bz = np.exp(-x)\n",
    "    return np.concatenate([rho, vx, vy, vz, P, Bx, By, Bz])\n",
    "\n",
    "# Dérivées spatiales (central diff, Neumann)\n",
    "def d_dx(u):\n",
    "    return np.gradient(u, dx)\n",
    "\n",
    "def d2_dx2(u):\n",
    "    return np.gradient(np.gradient(u, dx), dx)\n",
    "\n",
    "# Fonction du système ODE: dy/dt = ...\n",
    "def mhd_rhs(t, y):\n",
    "    f = forcing_terms(x, t)  # shape (8, N)\n",
    "\n",
    "    rho, vx, vy, vz, P, Bx, By, Bz = np.split(y, 8)\n",
    "\n",
    "    drho_dt = -vx * d_dx(rho) - rho * d_dx(vx) \n",
    "    dvx_dt = (-vx * d_dx(vx) - (1/rho) * d_dx(P)\n",
    "              - (1/rho)*(By * d_dx(By) + Bz * d_dx(Bz))\n",
    "              + mu * d2_dx2(vx) )\n",
    "    dvy_dt = (-vx * d_dx(vy) + (1/rho)*Bx*d_dx(By) )\n",
    "    dvz_dt = (-vx * d_dx(vz) + (1/rho)*Bx*d_dx(Bz) )\n",
    "    dP_dt = -P * d_dx(vx) - vx * d_dx(P) \n",
    "    dBx_dt = np.zeros_like(Bx) \n",
    "    dBy_dt = (-vx * d_dx(By) - By * d_dx(vx) + Bx * d_dx(vy) )\n",
    "    dBz_dt = (-vx * d_dx(Bz) - Bz * d_dx(vx) + Bx * d_dx(vz) )\n",
    "\n",
    "    # Forçage direct des variables aux bords\n",
    "    rho[0] = 2\n",
    "    vx[0] = vy[0] = vz[0] = 0\n",
    "    P[0] = Bx[0] = By[0] = Bz[0] = np.exp(-t)\n",
    "\n",
    "    return np.concatenate([drho_dt, dvx_dt, dvy_dt, dvz_dt, dP_dt, dBx_dt, dBy_dt, dBz_dt])\n",
    "\n",
    "# Résolution\n",
    "y0 = init_cond()\n",
    "solv1 = solve_ivp(mhd_rhs, (0, L), y0, method='RK45', t_eval=t_eval)\n",
    "\n",
    "# Extraction de vx numérique\n",
    "vx_num_v1 = solv1.y[6*nx:7*nx, :]  # shape (nx, nt), (0:nx) pour rho\n",
    "T, Xg = np.meshgrid(solv1.t, x)\n",
    "\n",
    "# Solution exacte (calculée mais non affichée)\n",
    "vx_ex = np.exp(-Xg)*np.exp(-T)\n",
    "err = vx_num_v1 - vx_ex\n",
    "\n",
    "# Préparation des données pour le PINN\n",
    "x_tensor = torch.tensor(Xg.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "t_tensor = torch.tensor(T.flatten(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prédiction PINN (en utilisant head_idx=1 pour la tête 2)\n",
    "with torch.no_grad():\n",
    "    if next(nets[1].parameters()).dtype != torch.float32:\n",
    "        for net in nets:\n",
    "            net.float()\n",
    "    vx_pinn_flat = solutions(x_tensor, t_tensor, head_idx=2)[3].cpu().numpy().flatten() ## head 1, rho\n",
    "\n",
    "vx_pinn = vx_pinn_flat.reshape(Xg.shape)\n",
    "\n",
    "\n",
    "# Configuration des graphiques (3 graphiques au lieu de 4)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Paramètres de style pour agrandir le texte\n",
    "fontsize = 14  # Taille de police pour les axes et titres\n",
    "cbar_fontsize = 14  # Taille de police pour la colorbar\n",
    "title_fontsize = 16  # Taille de police pour les titres\n",
    "\n",
    "# Graphique 1: Solution numérique\n",
    "plt.subplot(1, 3, 1)\n",
    "img1 = plt.pcolormesh(T, Xg, vx_num_v1, shading='auto', cmap='viridis')\n",
    "cbar1 = plt.colorbar(img1)\n",
    "cbar1.set_label('By', fontsize=cbar_fontsize)\n",
    "cbar1.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver solution', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 2: Prédiction PINN\n",
    "plt.subplot(1, 3, 2)\n",
    "img2 = plt.pcolormesh(T, Xg, vx_pinn, shading='auto', cmap='viridis')\n",
    "cbar2 = plt.colorbar(img2)\n",
    "cbar2.set_label('By', fontsize=cbar_fontsize)\n",
    "cbar2.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('PINN prediction(transfer learning using L-BFGS)', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "# Graphique 3: Différence Solveur-PINN\n",
    "plt.subplot(1, 3, 3)\n",
    "diff = vx_num_v1 - vx_pinn\n",
    "img3 = plt.pcolormesh(T, Xg, diff, shading='auto', cmap='bwr',\n",
    "               vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "cbar3 = plt.colorbar(img3)\n",
    "cbar3.set_label('Difference', fontsize=cbar_fontsize)\n",
    "cbar3.ax.tick_params(labelsize=cbar_fontsize)\n",
    "plt.xlabel('t', fontsize=fontsize)\n",
    "plt.ylabel('x', fontsize=fontsize)\n",
    "plt.title('Solver-PINN difference', fontsize=title_fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f85fd454c60ce05b55c93e7943429bfa634582618f1115d7922a9f3e7a477ae1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
